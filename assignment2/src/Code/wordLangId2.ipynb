{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jaeseung Lee"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-01T22:08:29.142378Z",
     "start_time": "2021-03-01T22:08:27.406020Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from math import log, exp\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import sys\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Training Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### English"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-01T22:08:29.232781Z",
     "start_time": "2021-03-01T22:08:29.211565Z"
    }
   },
   "outputs": [],
   "source": [
    "eng_input_path = \"../Data/Input/LangId.train.English\"\n",
    "\n",
    "# load english data, preprocessed data and save it\n",
    "with open(eng_input_path, \"r\") as eng_content:\n",
    "    \n",
    "    eng_preprocessed = []\n",
    "    for i in eng_content.readlines(): # read text line by line \n",
    "        \n",
    "        word = i.split() # split into letters\n",
    "        # remove punctuation at the end of the sentence\n",
    "        if word[-1] == '.' or word[-1]=='?' or word[-1]=='!':\n",
    "            word = word[:-1]\n",
    "        # add start and end of the letter for the bigram\n",
    "        word = ['<s>']+ word + ['</s>']\n",
    "\n",
    "        eng_preprocessed.append(word) # save it to the list\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### French"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-01T22:08:29.445345Z",
     "start_time": "2021-03-01T22:08:29.424406Z"
    }
   },
   "outputs": [],
   "source": [
    "fre_input_path = \"../Data/Input/LangId.train.French\"\n",
    "# load french data, preprocessed data and save it\n",
    "with open(fre_input_path, \"r\") as fre_content:\n",
    "    \n",
    "    fre_preprocessed = []\n",
    "    for i in fre_content.readlines(): # read text line by line \n",
    "        \n",
    "        \n",
    "        word = i.split() # split into letters\n",
    "        \n",
    "        # some empty list exists\n",
    "        if len(word) > 0:\n",
    "            \n",
    "            # remove punctuation at the end of the sentence\n",
    "            if word[-1] == '.' or word[-1]=='?' or word[-1]=='!':\n",
    "                word = word[:-1]\n",
    "                    \n",
    "            # add start and end of the letter for the bigram\n",
    "            word = ['<s>']+ word + ['</s>']\n",
    "\n",
    "            fre_preprocessed.append(word) # save it to the list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Italian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-01T22:08:30.073932Z",
     "start_time": "2021-03-01T22:08:30.052401Z"
    }
   },
   "outputs": [],
   "source": [
    "it_input_path = \"../Data/Input/LangId.train.Italian\"\n",
    "# load french data, preprocessed data and save it\n",
    "with open(it_input_path, \"r\") as it_content:\n",
    "    \n",
    "    it_preprocessed = []\n",
    "    for i in it_content.readlines(): # read text line by line \n",
    "        \n",
    "        \n",
    "        word = i.split() # split into letters\n",
    "        if len(word) > 0:\n",
    "                          \n",
    "           # remove punctuation at the end of the sentence\n",
    "            if word[-1] == '.' or word[-1]=='?' or word[-1]=='!':\n",
    "                word = word[:-1]\n",
    "                \n",
    "            # add start and end of the letter for the bigram\n",
    "            word = ['<s>']+ word + ['</s>']\n",
    "\n",
    "            it_preprocessed.append(word) # save it to the list\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-01T22:08:30.892881Z",
     "start_time": "2021-03-01T22:08:30.885181Z"
    }
   },
   "outputs": [],
   "source": [
    "test_path = \"../Data/Validation/LangId.test\"\n",
    "with open(test_path,\"r\") as test_content:\n",
    "    \n",
    "    test_preprocessed = []\n",
    "    \n",
    "    for i in test_content.readlines():\n",
    "        word = i.split()\n",
    "                \n",
    "        # remove punctuation at the end of the sentence\n",
    "        if word[-1] == '.' or word[-1]=='?' or word[-1]=='!':\n",
    "            word = word[:-1]\n",
    "            \n",
    "        # add start and end of the letter for the bigram\n",
    "        word = ['<s>']+ word + ['</s>']\n",
    "        test_preprocessed.append(word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Generate bigram model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-01T22:08:31.917983Z",
     "start_time": "2021-03-01T22:08:31.912118Z"
    }
   },
   "outputs": [],
   "source": [
    "def gen_bigram(data):\n",
    "    \n",
    "    bigram = {}\n",
    "    \n",
    "    for sent in data: # iterate sentence\n",
    "        for word in range(0, len(sent) -1): # iterate word in sentence\n",
    "            \n",
    "            # if word already exists in a bigram dictionary\n",
    "            if sent[word] in bigram.keys():\n",
    "                # if the next word already exists in the previous words dict, add 1\n",
    "                if sent[word+1] in bigram[sent[word]].keys():\n",
    "                    bigram[sent[word]][sent[word+1]] += 1\n",
    "                # if the next word not exists in the previous words dict, set as a key, and init the value to 1\n",
    "                else:\n",
    "                    bigram[sent[word]][sent[word+1]] = 1\n",
    "            # make key - value in dictionary, and init the value to 1\n",
    "            else: \n",
    "                bigram[sent[word]] = {}\n",
    "                bigram[sent[word]][sent[word + 1]] = 1\n",
    "#             break\n",
    "#         break\n",
    "    return bigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-01T22:08:34.461182Z",
     "start_time": "2021-03-01T22:08:34.400231Z"
    }
   },
   "outputs": [],
   "source": [
    "eng_bigram = gen_bigram(eng_preprocessed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-01T22:08:35.542866Z",
     "start_time": "2021-03-01T22:08:35.476353Z"
    }
   },
   "outputs": [],
   "source": [
    "fre_bigram = gen_bigram(fre_preprocessed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-01T22:08:36.789703Z",
     "start_time": "2021-03-01T22:08:36.732502Z"
    }
   },
   "outputs": [],
   "source": [
    "it_bigram = gen_bigram(it_preprocessed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-01T22:08:57.320806Z",
     "start_time": "2021-03-01T22:08:57.311342Z"
    }
   },
   "outputs": [],
   "source": [
    "def smooth_gt(model):\n",
    "    \n",
    "    # part 1 - setting up vars\n",
    "    c_nc = {}\n",
    "    \n",
    "    # below two lists are for linear regression\n",
    "    c = [] # contain c values, which is frequency value  \n",
    "    nc = [] # frequency of frequency c, contain Nc values\n",
    "    \n",
    "    # part 2\n",
    "    # model has nested-dictionary structure\n",
    "    # to count all the Nc, we need to use for loop twice\n",
    "    \n",
    "    # Build \"c_nc\" dictionary for smoothing model\n",
    "    for key in model.keys():\n",
    "\n",
    "        # iterate sub-dictionary\n",
    "        for sub_key in model[key].keys():\n",
    "\n",
    "            count = model[key][sub_key]\n",
    "            if count in c_nc.keys():\n",
    "                c_nc[count] += 1\n",
    "                \n",
    "            else:\n",
    "                c_nc[count] = 1\n",
    "\n",
    "                \n",
    "            if count in c:\n",
    "                nc[c.index(count)] += 1\n",
    "            else:\n",
    "                c.append(count)\n",
    "                nc.append(1)                \n",
    "\n",
    "    # part 3 - Simple good-turing\n",
    "    # In cases of Nc + 1 is zero or N_(c+1) does not exist, \n",
    "    # we have to estimate these value using linear regression\n",
    "    # f(n) = a + b*log(n)\n",
    "    log_nc = [log(y) for y in nc]\n",
    "    c = np.array(c).reshape(-1,1)\n",
    "    log_nc = np.array(log_nc)\n",
    "    reg = LinearRegression().fit(c, log_nc)\n",
    "    a = reg.intercept_\n",
    "#     print(\"INTERCEPT\",a)\n",
    "    b = reg.coef_\n",
    "#     print(\"COEF\",b)\n",
    "    \n",
    "    # part 4 - Update model\n",
    "    for key in model.keys():\n",
    "        for sub_key in model[key].keys():\n",
    "            count = model[key][sub_key]\n",
    "            \n",
    "            # if both Nc and Nc+1 are not 0, and \n",
    "            # if both (count+1) and (count) exist in c_nc dictionary,\n",
    "            # we can update using the formula (c+1)*Nc+1/Nc\n",
    "            if count+1 in c_nc.keys() and count in c_nc.keys():\n",
    "                model[key][sub_key] = (count+1)*(c_nc[count+1])/c_nc[count]\n",
    "                \n",
    "            # when Nc+1 is zero, or either (count+1) or (count) not exist in c_nc dictionary,\n",
    "            #  we can estime N_(c+1) using linear regression\n",
    "            else:\n",
    "#                 print(\"predict\", exp(reg.predict([[count+1],])))\n",
    "                model[key][sub_key] = (count+1)*(exp(reg.predict([[count+1],])))/c_nc[count]\n",
    "                                                 \n",
    "    # unseen case: N1/N                                               \n",
    "    model[\"unseen\"] = c_nc[1]/(len(model.keys())*len(model.keys())-sum(nc))\n",
    "#     print(\"N\", (len(model.keys())*len(model.keys())-sum(nc)))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-01T22:09:08.849735Z",
     "start_time": "2021-03-01T22:09:08.681135Z"
    }
   },
   "outputs": [],
   "source": [
    "eng_bigram_gt = smooth_gt(eng_bigram)\n",
    "fre_bigram_gt = smooth_gt(fre_bigram)\n",
    "it_bigram_gt = smooth_gt(it_bigram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-01T22:09:11.962084Z",
     "start_time": "2021-03-01T22:09:11.953242Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0005683761702188131, 0.0004082777949164141, 0.0003750029511272075)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eng_bigram_gt[\"unseen\"], fre_bigram_gt[\"unseen\"], it_bigram_gt[\"unseen\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Apply Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate probability for each language "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-01T22:09:25.726589Z",
     "start_time": "2021-03-01T22:09:25.721765Z"
    }
   },
   "outputs": [],
   "source": [
    "# word_prev: word_(n-1), word_n: word_(n)\n",
    "# We have to calculate this P(word_(n)| word_(n-1))\n",
    "\n",
    "def calc_prob_gt_smooth(model,word_prev,word_n):\n",
    "    \n",
    "    # start with 1, not zero which prevent return probability 0\n",
    "    count = 0\n",
    "    # As we started with 1, we have to add the total number of word tokens\n",
    "    total = 0\n",
    "    \n",
    "    # if there are word_(n-1) in the model,\n",
    "    if word_prev in model.keys():\n",
    "        \n",
    "        # iterate model by keys and count the total frequency of word_prev\n",
    "        for key in model[word_prev].keys():\n",
    "            total += model[word_prev][key]\n",
    "            \n",
    "        # if there are word_n in the dictionary of word_(n-1)\n",
    "        if word_n in model[word_prev].keys():\n",
    "            count = model[word_prev][word_n]   \n",
    "        else:\n",
    "            return model[\"unseen\"]\n",
    "    else:\n",
    "        return model[\"unseen\"]\n",
    "        \n",
    "    # calcuate the probability \n",
    "    result = count/total\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-01T22:09:28.861484Z",
     "start_time": "2021-03-01T22:09:28.857385Z"
    }
   },
   "outputs": [],
   "source": [
    "# word_prev: word_(n-1), word_n: word_(n)\n",
    "# We have to calculate this P(word_(n)| word_(n-1))\n",
    "\n",
    "def calc_prob(model,word_prev,word_n):\n",
    "    \n",
    "    # start with 1, not zero which prevent return probability 0\n",
    "    count = 0\n",
    "    # As we started with 1, we have to add the total number of word tokens\n",
    "    total = 0\n",
    "    \n",
    "    # if there are word_(n-1) in the model,\n",
    "    if word_prev in model.keys():\n",
    "        \n",
    "        # if there are word_n in the dictionary of word_(n-1)\n",
    "        if word_n in model[word_prev].keys():\n",
    "            count = model[word_prev][word_n]\n",
    "        else:\n",
    "            count = 0\n",
    "        \n",
    "        # iterate model by keys and count the total frequency of word_prev\n",
    "        for key in model[word_prev].keys():\n",
    "            total += model[word_prev][key]\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "    result = count/total\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Check Accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 1: with smoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-01T22:09:37.561840Z",
     "start_time": "2021-03-01T22:09:37.155965Z"
    }
   },
   "outputs": [],
   "source": [
    "output_path = \"../Data/Output/wordLangId2.out\"\n",
    "\n",
    "with open(output_path, \"w+\") as result:\n",
    "    # iterate test data by sentence\n",
    "    for idx, sent in enumerate(test_preprocessed):\n",
    "\n",
    "        prob_dict = {\"English\": 0, \"French\" : 0, \"Italian\" : 0}\n",
    "        # iterate words in sentence\n",
    "        for word in range(0, len(sent) -1):\n",
    "            # apply bigram model for english and calcuate probability\n",
    "            prob_dict[\"English\"] += calc_prob_gt_smooth(eng_bigram_gt,sent[word], sent[word+1])\n",
    "            # apply bigram model for french and calcuate probability\n",
    "            prob_dict[\"French\"] += calc_prob_gt_smooth(fre_bigram_gt,sent[word], sent[word+1])\n",
    "            # apply bigram model for italian and calcuate probability\n",
    "            prob_dict[\"Italian\"] += calc_prob_gt_smooth(it_bigram_gt,sent[word], sent[word+1])\n",
    "            \n",
    "        # compare probability and extract language with the high probability\n",
    "        lang = max(prob_dict, key=prob_dict.get)\n",
    "        result.write(str(idx+1) + \" \" + lang + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-01T22:09:40.701174Z",
     "start_time": "2021-03-01T22:09:40.697678Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "result_path = \"../Data/Output/wordLangId2.out\"\n",
    "with open(result_path, \"r\") as result:\n",
    "    result_list = []\n",
    "    for i in result.readlines():\n",
    "        result_list.append(i.split()[1])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-01T22:09:43.968879Z",
     "start_time": "2021-03-01T22:09:43.965427Z"
    }
   },
   "outputs": [],
   "source": [
    "ans_path = \"../Data/Validation/labels.sol\"\n",
    "with open(ans_path, \"r\") as ans:\n",
    "    ans_list = []\n",
    "    for i in ans.readlines():\n",
    "        ans_list.append(i.split()[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-01T22:09:47.334949Z",
     "start_time": "2021-03-01T22:09:47.322628Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Italian</td>\n",
       "      <td>Italian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>English</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Italian</td>\n",
       "      <td>Italian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>French</td>\n",
       "      <td>French</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>French</td>\n",
       "      <td>French</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>French</td>\n",
       "      <td>French</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>Italian</td>\n",
       "      <td>Italian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>Italian</td>\n",
       "      <td>Italian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>French</td>\n",
       "      <td>French</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>English</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>300 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       model   answer\n",
       "0    Italian  Italian\n",
       "1    English  English\n",
       "2    Italian  Italian\n",
       "3     French   French\n",
       "4     French   French\n",
       "..       ...      ...\n",
       "295   French   French\n",
       "296  Italian  Italian\n",
       "297  Italian  Italian\n",
       "298   French   French\n",
       "299  English  English\n",
       "\n",
       "[300 rows x 2 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = {\"model\": result_list, \"answer\":ans_list}\n",
    "df = pd.DataFrame(data)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-01T22:09:50.699082Z",
     "start_time": "2021-03-01T22:09:50.696483Z"
    }
   },
   "outputs": [],
   "source": [
    "def check_match(model,answer):\n",
    "    if model == answer:\n",
    "        result = 1\n",
    "    else:\n",
    "        result = 0\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-01T22:09:54.065205Z",
     "start_time": "2021-03-01T22:09:54.057003Z"
    }
   },
   "outputs": [],
   "source": [
    "df[\"match\"] = df[[\"model\", \"answer\"]].apply(lambda x: check_match(x[0],x[1]), axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-01T22:09:57.421819Z",
     "start_time": "2021-03-01T22:09:57.418788Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9866666666666667\n"
     ]
    }
   ],
   "source": [
    "acc = sum(df.match)/len(df)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 2: without smoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-01T22:10:15.407606Z",
     "start_time": "2021-03-01T22:10:15.038821Z"
    }
   },
   "outputs": [],
   "source": [
    "output_path = \"../Data/Output/wordLangId2_optional.out\"\n",
    "\n",
    "with open(output_path, \"w+\") as result:\n",
    "    # iterate test data by sentence\n",
    "    for idx, sent in enumerate(test_preprocessed):\n",
    "\n",
    "        prob_dict = {\"English\": 0, \"French\" : 0, \"Italian\" : 0}\n",
    "        # iterate words in sentence\n",
    "        for word in range(0, len(sent) -1):\n",
    "            # apply bigram model for english and calcuate probability\n",
    "            prob_dict[\"English\"] += calc_prob(eng_bigram,sent[word], sent[word+1])\n",
    "            # apply bigram model for french and calcuate probability\n",
    "            prob_dict[\"French\"] += calc_prob(fre_bigram,sent[word], sent[word+1])\n",
    "            # apply bigram model for italian and calcuate probability\n",
    "            prob_dict[\"Italian\"] += calc_prob(it_bigram,sent[word], sent[word+1])\n",
    "            \n",
    "        # compare probability and extract language with the high probability\n",
    "        lang = max(prob_dict, key=prob_dict.get)\n",
    "        result.write(str(idx+1) + \" \" + lang + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-01T22:10:18.542899Z",
     "start_time": "2021-03-01T22:10:18.539354Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "result_path = \"../Data/Output/wordLangId2_optional.out\"\n",
    "with open(result_path, \"r\") as result:\n",
    "    result_list = []\n",
    "    for i in result.readlines():\n",
    "        result_list.append(i.split()[1])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-01T22:10:21.679810Z",
     "start_time": "2021-03-01T22:10:21.675981Z"
    }
   },
   "outputs": [],
   "source": [
    "ans_path = \"../Data/Validation/labels.sol\"\n",
    "with open(ans_path, \"r\") as ans:\n",
    "    ans_list = []\n",
    "    for i in ans.readlines():\n",
    "        ans_list.append(i.split()[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-01T22:10:24.939699Z",
     "start_time": "2021-03-01T22:10:24.929548Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Italian</td>\n",
       "      <td>Italian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>English</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Italian</td>\n",
       "      <td>Italian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>French</td>\n",
       "      <td>French</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>French</td>\n",
       "      <td>French</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>French</td>\n",
       "      <td>French</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>Italian</td>\n",
       "      <td>Italian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>Italian</td>\n",
       "      <td>Italian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>French</td>\n",
       "      <td>French</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>English</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>300 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       model   answer\n",
       "0    Italian  Italian\n",
       "1    English  English\n",
       "2    Italian  Italian\n",
       "3     French   French\n",
       "4     French   French\n",
       "..       ...      ...\n",
       "295   French   French\n",
       "296  Italian  Italian\n",
       "297  Italian  Italian\n",
       "298   French   French\n",
       "299  English  English\n",
       "\n",
       "[300 rows x 2 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_opt = {\"model\": result_list, \"answer\":ans_list}\n",
    "df_opt = pd.DataFrame(data_opt)\n",
    "df_opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-01T22:10:28.347112Z",
     "start_time": "2021-03-01T22:10:28.344376Z"
    }
   },
   "outputs": [],
   "source": [
    "def check_match(model,answer):\n",
    "    if model == answer:\n",
    "        result = 1\n",
    "    else:\n",
    "        result = 0\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-01T22:10:31.715635Z",
     "start_time": "2021-03-01T22:10:31.708019Z"
    }
   },
   "outputs": [],
   "source": [
    "df_opt[\"match\"] = df_opt[[\"model\", \"answer\"]].apply(lambda x: check_match(x[0],x[1]), axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-01T22:10:35.149681Z",
     "start_time": "2021-03-01T22:10:35.147104Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.99\n"
     ]
    }
   ],
   "source": [
    "acc = sum(df_opt.match)/len(df_opt)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we use word bigram model, as you see without applying GT smoothing is better than applying the smoothing."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "160px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
