{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jaeseung Lee"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-01T22:12:38.478433Z",
     "start_time": "2021-03-01T22:12:38.475782Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Training Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### English"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-01T22:12:38.508956Z",
     "start_time": "2021-03-01T22:12:38.483698Z"
    }
   },
   "outputs": [],
   "source": [
    "eng_input_path = \"../Data/Input/LangId.train.English\"\n",
    "\n",
    "# load english data, preprocessed data and save it\n",
    "with open(eng_input_path, \"r\") as eng_content:\n",
    "    \n",
    "    eng_preprocessed = []\n",
    "    for i in eng_content.readlines(): # read text line by line \n",
    "        \n",
    "        \n",
    "        letters = list(i) # split into letters\n",
    "        letters = letters[:-2] # remove trailing whitespace\n",
    "        \n",
    "        if letters[0] == \"(\":\n",
    "            letters = letters[2:]\n",
    "        if letters[-1] == \" \":\n",
    "            letters = letters[:-1]\n",
    "            \n",
    "        # remove punctuation at the end of the sentence\n",
    "        if letters[-1] == '.' or letters[-1]=='?' or letters[-1]=='!':\n",
    "            letters = letters[:-1]\n",
    "            # sometimes there are white space between punctuation and last letter\n",
    "            # so remove white space after removing punctuation\n",
    "            if letters[-1] == ' ':\n",
    "                letters = letters[:-1]\n",
    "\n",
    "        # add start and end of the letter for the bigram\n",
    "        letters = ['<s>']+ letters + ['</s>']\n",
    "        eng_preprocessed.append(letters) # save it to the list\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### French"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-01T22:12:38.542166Z",
     "start_time": "2021-03-01T22:12:38.511664Z"
    }
   },
   "outputs": [],
   "source": [
    "fre_input_path = \"../Data/Input/LangId.train.French\"\n",
    "# load french data, preprocessed data and save it\n",
    "with open(fre_input_path, \"r\") as fre_content:\n",
    "    \n",
    "    fre_preprocessed = []\n",
    "    for i in fre_content.readlines(): # read text line by line \n",
    "        \n",
    "        \n",
    "        letters = list(i) # split into letters\n",
    "        \n",
    "        # some empty list exists\n",
    "        if len(letters) > 2:\n",
    "            \n",
    "            letters = letters[:-2] # remove trailing whitespace\n",
    "            \n",
    "            if letters[0] == \"(\" :\n",
    "                letters = letters[2:]\n",
    "            if letters[-1] == \" \":\n",
    "                letters = letters[:-1]\n",
    "            # remove punctuation at the end of the sentence\n",
    "            if letters[-1] == '.' or letters[-1]=='?' or letters[-1]=='!':\n",
    "                letters = letters[:-1]\n",
    "                # sometimes there are white space between punctuation and last letter\n",
    "                # so remove white space after removing punctuation\n",
    "                if letters[-1] == ' ':\n",
    "                    letters = letters[:-1]\n",
    "                \n",
    "                    \n",
    "            # add start and end of the letter for the bigram\n",
    "            letters = ['<s>']+ letters + ['</s>']\n",
    "\n",
    "            fre_preprocessed.append(letters) # save it to the list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Italian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-01T22:12:38.580900Z",
     "start_time": "2021-03-01T22:12:38.546335Z"
    }
   },
   "outputs": [],
   "source": [
    "it_input_path = \"../Data/Input/LangId.train.Italian\"\n",
    "# load french data, preprocessed data and save it\n",
    "with open(it_input_path, \"r\") as it_content:\n",
    "    \n",
    "    it_preprocessed = []\n",
    "    for i in it_content.readlines(): # read text line by line \n",
    "        \n",
    "        \n",
    "        letters = list(i) # split into letters\n",
    "        if len(letters) > 2:\n",
    "            letters = letters[:-2] # remove trailing whitespace\n",
    "            \n",
    "            if letters[0] == \"(\":\n",
    "                letters = letters[2:]\n",
    "                \n",
    "            if letters[-1] == \" \":\n",
    "                letters = letters[:-1]\n",
    "                \n",
    "            # remove punctuation at the end of the sentence\n",
    "            if letters[-1] == '.' or letters[-1]=='?' or letters[-1]=='!':\n",
    "                letters = letters[:-1]\n",
    "                # sometimes there are white space between punctuation and last letter\n",
    "                # so remove white space after removing punctuation\n",
    "                if letters[-1] == ' ':\n",
    "                    letters = letters[:-1]\n",
    "\n",
    "            # add start and end of the letter for the bigram\n",
    "            letters = ['<s>']+ letters + ['</s>']\n",
    "\n",
    "            it_preprocessed.append(letters) # save it to the list\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-01T22:12:38.592790Z",
     "start_time": "2021-03-01T22:12:38.583221Z"
    }
   },
   "outputs": [],
   "source": [
    "test_path = \"../Data/Validation/LangId.test\"\n",
    "with open(test_path,\"r\") as test_content:\n",
    "    \n",
    "    test_preprocessed = []\n",
    "    \n",
    "    for i in test_content.readlines():\n",
    "        letters = list(i)\n",
    "        \n",
    "        letters = letters[:-2] # remove trailing whitespace\n",
    "        \n",
    "        if letters[0] == \"(\" :\n",
    "                letters = letters[2:]\n",
    "        if letters[-1] == \" \":\n",
    "                letters = letters[:-1]\n",
    "        # remove punctuation at the end of the sentence\n",
    "        if letters[-1] == '.' or letters[-1]=='?' or letters[-1]=='!' or letters[-1]==';':\n",
    "            letters = letters[:-1]\n",
    "            # sometimes there are white space between punctuation and last letter\n",
    "            # so remove white space after removing punctuation\n",
    "            if letters[-1] == ' ':\n",
    "                letters = letters[:-1]\n",
    "                    \n",
    "            # add start and end of the letter for the bigram\n",
    "        letters = ['<s>']+ letters + ['</s>']\n",
    "        test_preprocessed.append(letters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Generate bigram model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-01T22:12:38.599115Z",
     "start_time": "2021-03-01T22:12:38.594260Z"
    }
   },
   "outputs": [],
   "source": [
    "def gen_bigram(data):\n",
    "    \n",
    "    bigram = {}\n",
    "    \n",
    "    for sent in data: # iterate sentence\n",
    "        for word in range(0, len(sent) -1): # iterate word in sentence\n",
    "            \n",
    "            # if word already exists in a bigram dictionary\n",
    "            if sent[word] in bigram.keys():\n",
    "                # if the next word already exists in the previous words dict, add 1\n",
    "                if sent[word+1] in bigram[sent[word]].keys():\n",
    "                    bigram[sent[word]][sent[word+1]] += 1\n",
    "                # if the next word not exists in the previous words dict, set as a key, and init the value to 1\n",
    "                else:\n",
    "                    bigram[sent[word]][sent[word+1]] = 1\n",
    "            # make key - value in dictionary, and init the value to 1\n",
    "            else: \n",
    "                bigram[sent[word]] = {}\n",
    "                bigram[sent[word]][sent[word + 1]] = 1\n",
    "#             break\n",
    "#         break\n",
    "    return bigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-01T22:12:38.782856Z",
     "start_time": "2021-03-01T22:12:38.600557Z"
    }
   },
   "outputs": [],
   "source": [
    "eng_bigram = gen_bigram(eng_preprocessed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-01T22:12:38.989436Z",
     "start_time": "2021-03-01T22:12:38.785185Z"
    }
   },
   "outputs": [],
   "source": [
    "fre_bigram = gen_bigram(fre_preprocessed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-01T22:12:39.199756Z",
     "start_time": "2021-03-01T22:12:38.991789Z"
    }
   },
   "outputs": [],
   "source": [
    "it_bigram = gen_bigram(it_preprocessed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Apply Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate probability for each language "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-01T22:12:39.208313Z",
     "start_time": "2021-03-01T22:12:39.203841Z"
    }
   },
   "outputs": [],
   "source": [
    "# word_prev: word_(n-1), word_n: word_(n)\n",
    "# We have to calculate this P(word_(n)| word_(n-1))\n",
    "def calc_prob(model,word_prev,word_n):\n",
    "    \n",
    "    \n",
    "    count = 0 # the number of times word_n appears in the model\n",
    "    total = 0 # total number of times word_(n-1) appers in the model\n",
    "    \n",
    "    # if there are word_(n-1) in the model,\n",
    "    if word_prev in model.keys():\n",
    "        \n",
    "        # if there are word_n in the dictionary of word_(n-1)\n",
    "        if word_n in model[word_prev].keys():\n",
    "            count = model[word_prev][word_n]\n",
    "        else:\n",
    "            count = 0\n",
    "        \n",
    "        # iterate model by keys and count the total frequency of word_prev\n",
    "        for key in model[word_prev].keys():\n",
    "            total += model[word_prev][key]\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "    result = count/total\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-01T22:12:39.739513Z",
     "start_time": "2021-03-01T22:12:39.211705Z"
    }
   },
   "outputs": [],
   "source": [
    "output_path = \"../Data/Output/letterLangId.out\"\n",
    "\n",
    "with open(output_path, \"w+\") as result:\n",
    "    # iterate test data by sentence\n",
    "    for idx, sent in enumerate(test_preprocessed):\n",
    "\n",
    "        prob_dict = {\"English\": 0, \"French\" : 0, \"Italian\" : 0}\n",
    "        # iterate words in sentence\n",
    "        for word in range(0, len(sent) -1):\n",
    "            # apply bigram model for english and calcuate probability\n",
    "            prob_dict[\"English\"] += calc_prob(eng_bigram,sent[word], sent[word+1])\n",
    "            # apply bigram model for french and calcuate probability\n",
    "            prob_dict[\"French\"] += calc_prob(fre_bigram,sent[word], sent[word+1])\n",
    "            # apply bigram model for italian and calcuate probability\n",
    "            prob_dict[\"Italian\"] += calc_prob(it_bigram,sent[word], sent[word+1])\n",
    "            \n",
    "        # compare probability and extract language with the high probability\n",
    "        lang = max(prob_dict, key=prob_dict.get)\n",
    "        result.write(str(idx+1) + \" \" + lang + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Check Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-01T22:12:40.486054Z",
     "start_time": "2021-03-01T22:12:39.741642Z"
    }
   },
   "outputs": [],
   "source": [
    "result_path = \"../Data/Output/letterLangId.out\"\n",
    "with open(result_path, \"r\") as result:\n",
    "    result_list = []\n",
    "    for i in result.readlines():\n",
    "        result_list.append(i.split()[1])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-01T22:12:40.491955Z",
     "start_time": "2021-03-01T22:12:40.487999Z"
    }
   },
   "outputs": [],
   "source": [
    "ans_path = \"../Data/Validation/labels.sol\"\n",
    "with open(ans_path, \"r\") as ans:\n",
    "    ans_list = []\n",
    "    for i in ans.readlines():\n",
    "        ans_list.append(i.split()[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-01T22:12:40.511009Z",
     "start_time": "2021-03-01T22:12:40.494184Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Italian</td>\n",
       "      <td>Italian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>English</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Italian</td>\n",
       "      <td>Italian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>French</td>\n",
       "      <td>French</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>French</td>\n",
       "      <td>French</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>French</td>\n",
       "      <td>French</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>Italian</td>\n",
       "      <td>Italian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>Italian</td>\n",
       "      <td>Italian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>French</td>\n",
       "      <td>French</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>English</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>300 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       model   answer\n",
       "0    Italian  Italian\n",
       "1    English  English\n",
       "2    Italian  Italian\n",
       "3     French   French\n",
       "4     French   French\n",
       "..       ...      ...\n",
       "295   French   French\n",
       "296  Italian  Italian\n",
       "297  Italian  Italian\n",
       "298   French   French\n",
       "299  English  English\n",
       "\n",
       "[300 rows x 2 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = {\"model\": result_list, \"answer\":ans_list}\n",
    "df = pd.DataFrame(data)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-01T22:12:40.517011Z",
     "start_time": "2021-03-01T22:12:40.513628Z"
    }
   },
   "outputs": [],
   "source": [
    "def check_match(model,answer):\n",
    "    if model == answer:\n",
    "        result = 1\n",
    "    else:\n",
    "        result = 0\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-01T22:12:40.528235Z",
     "start_time": "2021-03-01T22:12:40.518826Z"
    }
   },
   "outputs": [],
   "source": [
    "df[\"match\"] = df[[\"model\", \"answer\"]].apply(lambda x: check_match(x[0],x[1]), axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-01T22:12:40.532988Z",
     "start_time": "2021-03-01T22:12:40.530157Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9833333333333333\n"
     ]
    }
   ],
   "source": [
    "acc = sum(df.match)/len(df)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "160px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
