{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-01T22:19:48.696625Z",
     "start_time": "2021-03-01T22:19:48.688415Z"
    }
   },
   "source": [
    "Jaeseung Lee"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-01T06:52:48.373977Z",
     "start_time": "2021-03-01T06:52:48.371717Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Training Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### English"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-01T06:52:48.392315Z",
     "start_time": "2021-03-01T06:52:48.377425Z"
    }
   },
   "outputs": [],
   "source": [
    "eng_input_path = \"../Data/Input/LangId.train.English\"\n",
    "\n",
    "# load english data, preprocessed data and save it\n",
    "with open(eng_input_path, \"r\") as eng_content:\n",
    "    \n",
    "    eng_preprocessed = []\n",
    "    for i in eng_content.readlines(): # read text line by line \n",
    "        \n",
    "        word = i.split() # split into letters\n",
    "        # remove punctuation at the end of the sentence\n",
    "        if word[-1] == '.' or word[-1]=='?' or word[-1]=='!':\n",
    "            word = word[:-1]\n",
    "        # add start and end of the letter for the bigram\n",
    "        word = ['<s>']+ word + ['</s>']\n",
    "\n",
    "        eng_preprocessed.append(word) # save it to the list\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### French"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-01T06:52:48.417413Z",
     "start_time": "2021-03-01T06:52:48.394226Z"
    }
   },
   "outputs": [],
   "source": [
    "fre_input_path = \"../Data/Input/LangId.train.French\"\n",
    "# load french data, preprocessed data and save it\n",
    "with open(fre_input_path, \"r\") as fre_content:\n",
    "    \n",
    "    fre_preprocessed = []\n",
    "    for i in fre_content.readlines(): # read text line by line \n",
    "        \n",
    "        \n",
    "        word = i.split() # split into letters\n",
    "        \n",
    "        # some empty list exists\n",
    "        if len(word) > 0:\n",
    "            \n",
    "            # remove punctuation at the end of the sentence\n",
    "            if word[-1] == '.' or word[-1]=='?' or word[-1]=='!':\n",
    "                word = word[:-1]\n",
    "                    \n",
    "            # add start and end of the letter for the bigram\n",
    "            word = ['<s>']+ word + ['</s>']\n",
    "\n",
    "            fre_preprocessed.append(word) # save it to the list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Italian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-01T06:52:48.435298Z",
     "start_time": "2021-03-01T06:52:48.419621Z"
    }
   },
   "outputs": [],
   "source": [
    "it_input_path = \"../Data/Input/LangId.train.Italian\"\n",
    "# load french data, preprocessed data and save it\n",
    "with open(it_input_path, \"r\") as it_content:\n",
    "    \n",
    "    it_preprocessed = []\n",
    "    for i in it_content.readlines(): # read text line by line \n",
    "        \n",
    "        \n",
    "        word = i.split() # split into letters\n",
    "        if len(word) > 0:\n",
    "                          \n",
    "           # remove punctuation at the end of the sentence\n",
    "            if word[-1] == '.' or word[-1]=='?' or word[-1]=='!':\n",
    "                word = word[:-1]\n",
    "                \n",
    "            # add start and end of the letter for the bigram\n",
    "            word = ['<s>']+ word + ['</s>']\n",
    "\n",
    "            it_preprocessed.append(word) # save it to the list\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-01T06:52:48.443744Z",
     "start_time": "2021-03-01T06:52:48.437680Z"
    }
   },
   "outputs": [],
   "source": [
    "test_path = \"../Data/Validation/LangId.test\"\n",
    "with open(test_path,\"r\") as test_content:\n",
    "    \n",
    "    test_preprocessed = []\n",
    "    \n",
    "    for i in test_content.readlines():\n",
    "        word = i.split()\n",
    "                \n",
    "        # remove punctuation at the end of the sentence\n",
    "        if word[-1] == '.' or word[-1]=='?' or word[-1]=='!':\n",
    "            word = word[:-1]\n",
    "            \n",
    "        # add start and end of the letter for the bigram\n",
    "        word = ['<s>']+ word + ['</s>']\n",
    "        test_preprocessed.append(word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Generate bigram model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-01T06:52:48.450919Z",
     "start_time": "2021-03-01T06:52:48.445579Z"
    }
   },
   "outputs": [],
   "source": [
    "def gen_bigram(data):\n",
    "    \n",
    "    bigram = {}\n",
    "    \n",
    "    for sent in data: # iterate sentence\n",
    "        for word in range(0, len(sent) -1): # iterate word in sentence\n",
    "            \n",
    "            # if word already exists in a bigram dictionary\n",
    "            if sent[word] in bigram.keys():\n",
    "                # if the next word already exists in the previous words dict, add 1\n",
    "                if sent[word+1] in bigram[sent[word]].keys():\n",
    "                    bigram[sent[word]][sent[word+1]] += 1\n",
    "                # if the next word not exists in the previous words dict, set as a key, and init the value to 1\n",
    "                else:\n",
    "                    bigram[sent[word]][sent[word+1]] = 1\n",
    "            # make key - value in dictionary, and init the value to 1\n",
    "            else: \n",
    "                bigram[sent[word]] = {}\n",
    "                bigram[sent[word]][sent[word + 1]] = 1\n",
    "#             break\n",
    "#         break\n",
    "    return bigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-01T06:52:48.523389Z",
     "start_time": "2021-03-01T06:52:48.452398Z"
    }
   },
   "outputs": [],
   "source": [
    "eng_bigram = gen_bigram(eng_preprocessed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-01T06:52:48.588671Z",
     "start_time": "2021-03-01T06:52:48.524907Z"
    }
   },
   "outputs": [],
   "source": [
    "fre_bigram = gen_bigram(fre_preprocessed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-01T06:52:48.646011Z",
     "start_time": "2021-03-01T06:52:48.590768Z"
    }
   },
   "outputs": [],
   "source": [
    "it_bigram = gen_bigram(it_preprocessed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Apply Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate probability for each language "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-01T06:54:36.137315Z",
     "start_time": "2021-03-01T06:54:36.132797Z"
    }
   },
   "outputs": [],
   "source": [
    "# word_prev: word_(n-1), word_n: word_(n)\n",
    "# We have to calculate this P(word_(n)| word_(n-1))\n",
    "\n",
    "def calc_prob_la_smooth(model,word_prev,word_n):\n",
    "    \n",
    "    # start with 1, not zero which prevent return probability 0\n",
    "    count = 1\n",
    "    # As we started with 1, we have to add the total number of word tokens\n",
    "    total = len(model.keys())\n",
    "    \n",
    "    \n",
    "    # if there are word_(n-1) in the model,\n",
    "    if word_prev in model.keys():\n",
    "\n",
    "        # iterate model by keys and count the total frequency of word_prev\n",
    "        for key in model[word_prev].keys():\n",
    "            total += model[word_prev][key]\n",
    "            \n",
    "        # if there are word_n in the dictionary of word_(n-1)\n",
    "        if word_n in model[word_prev].keys():\n",
    "            count = model[word_prev][word_n]\n",
    "\n",
    "\n",
    "    # calcuate the probability \n",
    "    result = count/total\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-01T06:54:36.700180Z",
     "start_time": "2021-03-01T06:54:36.696554Z"
    }
   },
   "outputs": [],
   "source": [
    "# word_prev: word_(n-1), word_n: word_(n)\n",
    "# We have to calculate this P(word_(n)| word_(n-1))\n",
    "\n",
    "def calc_prob(model,word_prev,word_n):\n",
    "    \n",
    "    count = 0\n",
    "    total = 0\n",
    "    \n",
    "    # if there are word_(n-1) in the model,\n",
    "    if word_prev in model.keys():\n",
    "\n",
    "        \n",
    "        # iterate model by keys and count the total frequency of word_prev\n",
    "        for key in model[word_prev].keys():\n",
    "            total += model[word_prev][key]\n",
    "            \n",
    "        # if there are word_n in the dictionary of word_(n-1)\n",
    "        if word_n in model[word_prev].keys():\n",
    "            count = model[word_prev][word_n]\n",
    "        else:\n",
    "            count = 0\n",
    "        \n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "    result = count/total\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-01T06:54:37.637899Z",
     "start_time": "2021-03-01T06:54:37.226371Z"
    }
   },
   "outputs": [],
   "source": [
    "output_path = \"../Data/Output/wordLangId.out\"\n",
    "\n",
    "with open(output_path, \"w+\") as result:\n",
    "    # iterate test data by sentence\n",
    "    for idx, sent in enumerate(test_preprocessed):\n",
    "\n",
    "        prob_dict = {\"English\": 0, \"French\" : 0, \"Italian\" : 0}\n",
    "        # iterate words in sentence\n",
    "        for word in range(0, len(sent) -1):\n",
    "            # apply bigram model for english and calcuate probability\n",
    "            prob_dict[\"English\"] += calc_prob_la_smooth(eng_bigram,sent[word], sent[word+1])\n",
    "            # apply bigram model for french and calcuate probability\n",
    "            prob_dict[\"French\"] += calc_prob_la_smooth(fre_bigram,sent[word], sent[word+1])\n",
    "            # apply bigram model for italian and calcuate probability\n",
    "            prob_dict[\"Italian\"] += calc_prob_la_smooth(it_bigram,sent[word], sent[word+1])\n",
    "            \n",
    "        # compare probability and extract language with the high probability\n",
    "        lang = max(prob_dict, key=prob_dict.get)\n",
    "        result.write(str(idx+1) + \" \" + lang + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Check Accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 1: with smoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-01T06:54:38.989875Z",
     "start_time": "2021-03-01T06:54:38.572127Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "result_path = \"../Data/Output/wordLangId.out\"\n",
    "with open(result_path, \"r\") as result:\n",
    "    result_list = []\n",
    "    for i in result.readlines():\n",
    "        result_list.append(i.split()[1])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-01T06:54:39.532094Z",
     "start_time": "2021-03-01T06:54:39.528004Z"
    }
   },
   "outputs": [],
   "source": [
    "ans_path = \"../Data/Validation/labels.sol\"\n",
    "with open(ans_path, \"r\") as ans:\n",
    "    ans_list = []\n",
    "    for i in ans.readlines():\n",
    "        ans_list.append(i.split()[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-01T06:54:40.105700Z",
     "start_time": "2021-03-01T06:54:40.059266Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Italian</td>\n",
       "      <td>Italian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>English</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Italian</td>\n",
       "      <td>Italian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>French</td>\n",
       "      <td>French</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>French</td>\n",
       "      <td>French</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>French</td>\n",
       "      <td>French</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>Italian</td>\n",
       "      <td>Italian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>Italian</td>\n",
       "      <td>Italian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>French</td>\n",
       "      <td>French</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>English</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>300 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       model   answer\n",
       "0    Italian  Italian\n",
       "1    English  English\n",
       "2    Italian  Italian\n",
       "3     French   French\n",
       "4     French   French\n",
       "..       ...      ...\n",
       "295   French   French\n",
       "296  Italian  Italian\n",
       "297  Italian  Italian\n",
       "298   French   French\n",
       "299  English  English\n",
       "\n",
       "[300 rows x 2 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = {\"model\": result_list, \"answer\":ans_list}\n",
    "df = pd.DataFrame(data)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-01T06:54:40.669924Z",
     "start_time": "2021-03-01T06:54:40.667298Z"
    }
   },
   "outputs": [],
   "source": [
    "def check_match(model,answer):\n",
    "    if model == answer:\n",
    "        result = 1\n",
    "    else:\n",
    "        result = 0\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-01T06:54:41.394260Z",
     "start_time": "2021-03-01T06:54:41.383632Z"
    }
   },
   "outputs": [],
   "source": [
    "df[\"match\"] = df[[\"model\", \"answer\"]].apply(lambda x: check_match(x[0],x[1]), axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-01T06:54:41.985140Z",
     "start_time": "2021-03-01T06:54:41.982429Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9433333333333334\n"
     ]
    }
   ],
   "source": [
    "acc = sum(df.match)/len(df)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 2: without smoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-01T06:54:44.191646Z",
     "start_time": "2021-03-01T06:54:43.781108Z"
    }
   },
   "outputs": [],
   "source": [
    "output_path = \"../Data/Output/wordLangId_optional.out\"\n",
    "\n",
    "with open(output_path, \"w+\") as result:\n",
    "    # iterate test data by sentence\n",
    "    for idx, sent in enumerate(test_preprocessed):\n",
    "\n",
    "        prob_dict = {\"English\": 0, \"French\" : 0, \"Italian\" : 0}\n",
    "        # iterate words in sentence\n",
    "        for word in range(0, len(sent) -1):\n",
    "            # apply bigram model for english and calcuate probability\n",
    "            prob_dict[\"English\"] += calc_prob(eng_bigram,sent[word], sent[word+1])\n",
    "            # apply bigram model for french and calcuate probability\n",
    "            prob_dict[\"French\"] += calc_prob(fre_bigram,sent[word], sent[word+1])\n",
    "            # apply bigram model for italian and calcuate probability\n",
    "            prob_dict[\"Italian\"] += calc_prob(it_bigram,sent[word], sent[word+1])\n",
    "            \n",
    "        # compare probability and extract language with the high probability\n",
    "        lang = max(prob_dict, key=prob_dict.get)\n",
    "        result.write(str(idx+1) + \" \" + lang + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-01T06:54:44.756341Z",
     "start_time": "2021-03-01T06:54:44.752387Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "result_path = \"../Data/Output/wordLangId_optional.out\"\n",
    "with open(result_path, \"r\") as result:\n",
    "    result_list = []\n",
    "    for i in result.readlines():\n",
    "        result_list.append(i.split()[1])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-01T06:54:45.320323Z",
     "start_time": "2021-03-01T06:54:45.316891Z"
    }
   },
   "outputs": [],
   "source": [
    "ans_path = \"../Data/Validation/labels.sol\"\n",
    "with open(ans_path, \"r\") as ans:\n",
    "    ans_list = []\n",
    "    for i in ans.readlines():\n",
    "        ans_list.append(i.split()[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-01T06:54:45.894029Z",
     "start_time": "2021-03-01T06:54:45.884867Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Italian</td>\n",
       "      <td>Italian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>English</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Italian</td>\n",
       "      <td>Italian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>French</td>\n",
       "      <td>French</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>French</td>\n",
       "      <td>French</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>French</td>\n",
       "      <td>French</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>Italian</td>\n",
       "      <td>Italian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>Italian</td>\n",
       "      <td>Italian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>French</td>\n",
       "      <td>French</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>English</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>300 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       model   answer\n",
       "0    Italian  Italian\n",
       "1    English  English\n",
       "2    Italian  Italian\n",
       "3     French   French\n",
       "4     French   French\n",
       "..       ...      ...\n",
       "295   French   French\n",
       "296  Italian  Italian\n",
       "297  Italian  Italian\n",
       "298   French   French\n",
       "299  English  English\n",
       "\n",
       "[300 rows x 2 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_opt = {\"model\": result_list, \"answer\":ans_list}\n",
    "df_opt = pd.DataFrame(data_opt)\n",
    "df_opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-01T06:54:46.476195Z",
     "start_time": "2021-03-01T06:54:46.473501Z"
    }
   },
   "outputs": [],
   "source": [
    "def check_match(model,answer):\n",
    "    if model == answer:\n",
    "        result = 1\n",
    "    else:\n",
    "        result = 0\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-01T06:54:47.073258Z",
     "start_time": "2021-03-01T06:54:47.067027Z"
    }
   },
   "outputs": [],
   "source": [
    "df_opt[\"match\"] = df_opt[[\"model\", \"answer\"]].apply(lambda x: check_match(x[0],x[1]), axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-01T06:54:47.645472Z",
     "start_time": "2021-03-01T06:54:47.642027Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.99\n"
     ]
    }
   ],
   "source": [
    "acc = sum(df_opt.match)/len(df_opt)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we use word bigram model, as you see without applying lapace smoothing is better than applying the smoothing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "160px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
